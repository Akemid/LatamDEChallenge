{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ENGINEER CHALLENGE\n",
    "\n",
    "Para el desarrollo de este challenge estoy utilizando Python 3.12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descomprimir el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import unzip_json\n",
    "file_path = \"datasets/tweets.json.zip\"\n",
    "output_dir = \"datasets/\"\n",
    "output_file_path = \"datasets/farmers-protest-tweets-2021-2-4.json\"\n",
    "if not os.path.exists(output_file_path):\n",
    "    unzip_json(file_path,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "Primero se intentó agregar todo el json en un dataframe en pandas, reduciendo el uso de memoria utilizando el chunksize y solo dejando las columnas que eran necesarias. Se probaron con distintos chunksize para ver el cambio del uso de la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_memory import q1_memory_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   109 159.4141 MiB 159.4141 MiB           1   @profile(precision=4)\n",
      "   110                                         def q1_memory_pandas(file_path: str,chunksize=1000) -> List[Tuple[datetime.date, str]]:\n",
      "   111 159.5391 MiB   0.1250 MiB           1       tweets = pd.read_json(file_path, lines=True,chunksize=chunksize,convert_dates=True)\n",
      "   112 159.5391 MiB   0.0000 MiB           1       procced_tweets = map(process_tweets, tweets)\n",
      "   113 192.0273 MiB  32.4883 MiB           1       result = reduce(add, procced_tweets)\n",
      "   114 192.2773 MiB   0.2500 MiB           1       top_dates = result.groupby(['date']).sum().sort_values(ascending=False).head(10).index.values.tolist()\n",
      "   115 192.2773 MiB   0.0000 MiB           1       users = []\n",
      "   116 192.2773 MiB   0.0000 MiB           1       result = result.reset_index()    \n",
      "   117 192.4023 MiB   0.0000 MiB          11       for date in top_dates:\n",
      "   118 192.4023 MiB   0.1250 MiB          10           top_twitter_user = result[result['date'] == date][[\"user\",0]]\n",
      "   119 192.4023 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.groupby(['user']).sum()    \n",
      "   120 192.4023 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.sort_values(by=0,ascending=False).head(1).index.values.tolist()[0]\n",
      "   121                                                 # print(top_twitter_user)\n",
      "   122 192.4023 MiB   0.0000 MiB          10           users.append(top_twitter_user)\n",
      "   123 192.4023 MiB   0.0000 MiB           1       return list(zip(top_dates, users)) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = q1_memory_pandas(output_file_path,chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   109 157.2891 MiB 157.2891 MiB           1   @profile(precision=4)\n",
      "   110                                         def q1_memory_pandas(file_path: str,chunksize=1000) -> List[Tuple[datetime.date, str]]:\n",
      "   111 157.2891 MiB   0.0000 MiB           1       tweets = pd.read_json(file_path, lines=True,chunksize=chunksize,convert_dates=True)\n",
      "   112 157.2891 MiB   0.0000 MiB           1       procced_tweets = map(process_tweets, tweets)\n",
      "   113 214.9414 MiB  57.6523 MiB           1       result = reduce(add, procced_tweets)\n",
      "   114 215.3164 MiB   0.3750 MiB           1       top_dates = result.groupby(['date']).sum().sort_values(ascending=False).head(10).index.values.tolist()\n",
      "   115 215.3164 MiB   0.0000 MiB           1       users = []\n",
      "   116 215.3164 MiB   0.0000 MiB           1       result = result.reset_index()    \n",
      "   117 215.3164 MiB   0.0000 MiB          11       for date in top_dates:\n",
      "   118 215.3164 MiB   0.0000 MiB          10           top_twitter_user = result[result['date'] == date][[\"user\",0]]\n",
      "   119 215.3164 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.groupby(['user']).sum()    \n",
      "   120 215.3164 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.sort_values(by=0,ascending=False).head(1).index.values.tolist()[0]\n",
      "   121                                                 # print(top_twitter_user)\n",
      "   122 215.3164 MiB   0.0000 MiB          10           users.append(top_twitter_user)\n",
      "   123 215.3164 MiB   0.0000 MiB           1       return list(zip(top_dates, users)) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = q1_memory_pandas(output_file_path,chunksize=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   109 152.0859 MiB 152.0859 MiB           1   @profile(precision=4)\n",
      "   110                                         def q1_memory_pandas(file_path: str,chunksize=1000) -> List[Tuple[datetime.date, str]]:\n",
      "   111 152.0859 MiB   0.0000 MiB           1       tweets = pd.read_json(file_path, lines=True,chunksize=chunksize,convert_dates=True)\n",
      "   112 152.0859 MiB   0.0000 MiB           1       procced_tweets = map(process_tweets, tweets)\n",
      "   113 175.2500 MiB  23.1641 MiB           1       result = reduce(add, procced_tweets)\n",
      "   114 175.5000 MiB   0.2500 MiB           1       top_dates = result.groupby(['date']).sum().sort_values(ascending=False).head(10).index.values.tolist()\n",
      "   115 175.5000 MiB   0.0000 MiB           1       users = []\n",
      "   116 175.5000 MiB   0.0000 MiB           1       result = result.reset_index()    \n",
      "   117 175.5000 MiB   0.0000 MiB          11       for date in top_dates:\n",
      "   118 175.5000 MiB   0.0000 MiB          10           top_twitter_user = result[result['date'] == date][[\"user\",0]]\n",
      "   119 175.5000 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.groupby(['user']).sum()    \n",
      "   120 175.5000 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.sort_values(by=0,ascending=False).head(1).index.values.tolist()[0]\n",
      "   121                                                 # print(top_twitter_user)\n",
      "   122 175.5000 MiB   0.0000 MiB          10           users.append(top_twitter_user)\n",
      "   123 175.5000 MiB   0.0000 MiB           1       return list(zip(top_dates, users)) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = q1_memory_pandas(output_file_path,chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe con tipos definidos pero con pérdida de datos no necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    71 153.3594 MiB 153.3594 MiB           1   @profile(precision=4)\n",
      "    72                                         def q1_memory_pandas_types(file_path: str,chunksize=1000) -> List[Tuple[datetime.date, str]]:\n",
      "    73 153.3594 MiB   0.0000 MiB          19       tweets = pd.read_json(file_path, lines=True,chunksize=chunksize,convert_dates=True,dtype={\n",
      "    74 153.3594 MiB   0.0000 MiB           1           \"url\":\"bool\",\n",
      "    75 153.3594 MiB   0.0000 MiB           1           \"date\":\"datetime64[ns]\",\n",
      "    76 153.3594 MiB   0.0000 MiB           1           \"content\":\"bool\",\n",
      "    77 153.3594 MiB   0.0000 MiB           1           \"renderedContent\": \"bool\",\n",
      "    78 153.3594 MiB   0.0000 MiB           1           \"id\": \"bool\",\n",
      "    79 153.3594 MiB   0.0000 MiB           1           \"user\":\"object\",\n",
      "    80 153.3594 MiB   0.0000 MiB           1           \"outlinks\":\"bool\",\n",
      "    81 153.3594 MiB   0.0000 MiB           1           \"tcooutlinks\":\"bool\",\n",
      "    82 153.3594 MiB   0.0000 MiB           1           \"replyCount\":\"bool\",\n",
      "    83 153.3594 MiB   0.0000 MiB           1           \"retweetCount\":\"bool\",\n",
      "    84 153.3594 MiB   0.0000 MiB           1           \"likeCount\":\"bool\",\n",
      "    85 153.3594 MiB   0.0000 MiB           1           \"quoteCount\":\"bool\",\n",
      "    86 153.3594 MiB   0.0000 MiB           1           \"conversationId\":\"bool\",\n",
      "    87 153.3594 MiB   0.0000 MiB           1           \"lang\":\"bool\",\n",
      "    88 153.3594 MiB   0.0000 MiB           1           \"source\":\"bool\",\n",
      "    89 153.3594 MiB   0.0000 MiB           1           \"sourceUrl\":\"bool\",\n",
      "    90 153.3594 MiB   0.0000 MiB           1           \"sourceLabel\":\"bool\",\n",
      "    91 153.3594 MiB   0.0000 MiB           1           \"media\":\"bool\",\n",
      "    92 153.3594 MiB   0.0000 MiB           1           \"retweetedTweet\":\"bool\",\n",
      "    93 153.3594 MiB   0.0000 MiB           1           \"quotedTweet\":\"bool\",\n",
      "    94 153.3594 MiB   0.0000 MiB           1           \"mentionedUsers\":\"bool\",\n",
      "    95                                             })\n",
      "    96 153.3594 MiB   0.0000 MiB           1       procced_tweets = map(process_tweets, tweets)\n",
      "    97 186.7148 MiB  33.3555 MiB           1       result = reduce(add, procced_tweets)\n",
      "    98 187.0898 MiB   0.3750 MiB           1       top_dates = result.groupby(['date']).sum().sort_values(ascending=False).head(10).index.values.tolist()\n",
      "    99 187.0898 MiB   0.0000 MiB           1       users = []\n",
      "   100 187.0898 MiB   0.0000 MiB           1       result = result.reset_index()    \n",
      "   101 187.0898 MiB   0.0000 MiB          11       for date in top_dates:\n",
      "   102 187.0898 MiB   0.0000 MiB          10           top_twitter_user = result[result['date'] == date][[\"user\",0]]\n",
      "   103 187.0898 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.groupby(['user']).sum()    \n",
      "   104 187.0898 MiB   0.0000 MiB          10           top_twitter_user = top_twitter_user.sort_values(by=0,ascending=False).head(1).index.values.tolist()[0]\n",
      "   105                                                 # print(top_twitter_user)\n",
      "   106 187.0898 MiB   0.0000 MiB          10           users.append(top_twitter_user)\n",
      "   107 187.0898 MiB   0.0000 MiB           1       return list(zip(top_dates, users)) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import  q1_memory_pandas_types\n",
    "result = q1_memory_pandas_types(output_file_path,chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars\n",
    "Una alternativa a pandas la cual utiliza código de bajo nivel para optimizar la memoria y el tiempo. Gracias a sus lazy dataframes le permite tener mejores resultados que pandas. Sin embargo al utilizar hilos paralelos puede consumir mucha más memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   142    152.1 MiB    152.1 MiB           1   @profile \n",
      "   143                                         def read_lazy_json(file_path:str):\n",
      "   144    154.9 MiB      2.9 MiB           1       tweets = pl.scan_ndjson(file_path,low_memory=True)\n",
      "   145    156.2 MiB      0.5 MiB           2       tweets = tweets.select(\n",
      "   146    155.7 MiB      0.8 MiB           1           [pl.col(\"date\").cast(pl.Datetime).cast(pl.Date), pl.col(\"user\").struct.field(\"username\").alias(\"user\")]\n",
      "   147                                             )\n",
      "   148    156.3 MiB      0.1 MiB           2       tweets = tweets.group_by([\"date\",\"user\"]).agg(\n",
      "   149    156.2 MiB      0.0 MiB           1             pl.col(\"date\").count().alias(\"count\"),\n",
      "   150                                                 )    \n",
      "   151    156.3 MiB      0.0 MiB           3       tweets = tweets.sort(\n",
      "   152    156.3 MiB      0.0 MiB           1           by=[\"date\",\"count\"],descending=True\n",
      "   153    156.3 MiB      0.0 MiB           2           ).group_by(\"date\").agg(\n",
      "   154    156.3 MiB      0.0 MiB           1               pl.col(\"date\").count().alias(\"count\"),\n",
      "   155    156.3 MiB      0.0 MiB           1               pl.col(\"user\").first().alias(\"user\")\n",
      "   156    156.3 MiB      0.0 MiB           2           ).sort(\n",
      "   157    156.3 MiB      0.0 MiB           1               by=\"count\",descending=True\n",
      "   158    156.3 MiB      0.0 MiB           2           ).limit(10).select(\n",
      "   159    156.3 MiB      0.0 MiB           1               pl.col(\"date\"),\n",
      "   160    156.3 MiB      0.0 MiB           1               pl.col(\"user\")\n",
      "   161                                                 )\n",
      "   162    156.3 MiB      0.0 MiB           1       return tweets\n",
      "\n",
      "\n",
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   135 152.0703 MiB 152.0703 MiB           1   @profile(precision=4)\n",
      "   136                                         def q1_memory_polars(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "   137 156.3203 MiB   4.2500 MiB           1       query = read_lazy_json(file_path)\n",
      "   138                                             # query = query.top_k(10,by=\"count\")\n",
      "   139 1106.1133 MiB 949.7930 MiB           1       result = query.collect()\n",
      "   140 1106.2383 MiB   0.1250 MiB           1       return result.rows()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory_polars\n",
    "result = q1_memory_polars(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linea por linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    23 152.2227 MiB 152.2227 MiB           1   @profile(precision=4)\n",
      "    24                                         def q1_memory_line_by_line(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    25                                             # We need to optimize the memory\n",
      "    26                                             # Read line by line using json\n",
      "    27 156.3477 MiB   0.0000 MiB          27       tweets_dict = defaultdict(lambda: defaultdict(int))\n",
      "    28 157.0977 MiB   0.1250 MiB           2       with open(file_path, 'r', encoding='utf-8') as file:\n",
      "    29                                                 # Read line by line\n",
      "    30 157.0977 MiB   0.2500 MiB      117408           for line in file:\n",
      "    31                                                     # Load the json\n",
      "    32 157.0977 MiB   3.2500 MiB      117407               tweet = json.loads(line)\n",
      "    33                                                     # Extract the date and convert into date \n",
      "    34 157.0977 MiB   0.0000 MiB      117407               date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
      "    35                                                     # Extract the username\n",
      "    36 157.0977 MiB   0.0000 MiB      117407               username = tweet['user']['username']\n",
      "    37                                                     # Count by date and username\n",
      "    38 157.0977 MiB   1.2500 MiB      117407               tweets_dict[date][username] += 1\n",
      "    39                                             # Get all the data in form of item (date, {user:count})\n",
      "    40 157.0977 MiB   0.0000 MiB           1       tweet_dict_items = tweets_dict.items()\n",
      "    41                                             # Sort the dates by the sum of the tweets counts of each user and order desc\n",
      "    42 157.0977 MiB   0.0000 MiB          27       tweets_dict = sorted(tweet_dict_items, key=lambda x:sum(x[1].values()), reverse=True)\n",
      "    43                                             # Get the top 10 dates\n",
      "    44 157.0977 MiB   0.0000 MiB           1       tweets_dict = tweets_dict[:10]\n",
      "    45                                             # Get in dict format\n",
      "    46 157.0977 MiB   0.0000 MiB           1       tweets_dict = dict(tweets_dict)\n",
      "    47                                             # Creating a list with comprehension in order to save memory\n",
      "    48 157.0977 MiB   0.0000 MiB          11       users_top_tweets = [\n",
      "    49                                                                 # Get the user with the most tweets for each date\n",
      "    50 157.0977 MiB   0.0000 MiB       88328                           max(tweets_dict[date],key=lambda x: tweets_dict[date][x])\n",
      "    51 157.0977 MiB   0.0000 MiB          11                           for date in tweets_dict.keys()\n",
      "    52                                                                 ]        \n",
      "    53 157.0977 MiB   0.0000 MiB           1       return list(zip(tweets_dict.keys(), users_top_tweets))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory_line_by_line\n",
    "\n",
    "result = q1_memory_line_by_line(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    47 152.2734 MiB 152.2734 MiB           1   @profile(precision=4)\n",
      "    48                                         def q1_memory_line_by_line_alt(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    49                                             # We need to optimize the memory\n",
      "    50                                             # Read line by line using json\n",
      "    51 156.2734 MiB   0.0000 MiB          27       tweets_dict = defaultdict(lambda: defaultdict(int))\n",
      "    52 156.8984 MiB   0.0000 MiB           2       with open(file_path, 'r', encoding='utf-8') as file:\n",
      "    53                                                 # Read line by line\n",
      "    54 156.8984 MiB   0.2500 MiB      117408           for line in file:\n",
      "    55                                                     # Load the json\n",
      "    56 156.8984 MiB   3.1250 MiB      117407               tweet = json.loads(line)\n",
      "    57                                                     # Extract the date and convert into date \n",
      "    58 156.8984 MiB   0.1250 MiB      117407               date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
      "    59                                                     # Extract the username\n",
      "    60 156.8984 MiB   0.0000 MiB      117407               username = tweet['user']['username']\n",
      "    61                                                     # Count by date and username\n",
      "    62 156.8984 MiB   1.1250 MiB      117407               tweets_dict[date][username] += 1\n",
      "    63                                                     \n",
      "    64 156.8984 MiB   0.0000 MiB          27       tweet_date_dict = dict(sorted(tweets_dict.items(), key=lambda x:sum(x[1].values()), reverse=True)[:10])\n",
      "    65 156.8984 MiB   0.0000 MiB       88329       users_top_tweets = [max(tweets_dict[date],key=lambda x: tweets_dict[date][x]) for date in tweet_date_dict.keys()]\n",
      "    66 156.8984 MiB   0.0000 MiB           1       return list(zip(tweet_date_dict.keys(), users_top_tweets))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory_line_by_line_alt\n",
    "\n",
    "result = q1_memory_line_by_line_alt(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linea por linea con streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/admintdp/Documentos/personalProyects/challenge_DE/src/q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    42 152.0273 MiB 152.0273 MiB           1   @profile(precision=4)   \n",
      "    43                                         def q1_memory_ijson(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    44                                             # We need to optimize the memory\n",
      "    45                                             # So we need to read the file line by line or on streaming mode\n",
      "    46                                             # Read line by line using json\n",
      "    47                                             \n",
      "    48 156.5273 MiB   0.0000 MiB          27       tweets_dict = defaultdict(lambda: defaultdict(int))\n",
      "    49 157.1523 MiB   0.0000 MiB           2       with open(file_path, 'r', encoding='utf-8') as file:\n",
      "    50                                                 # Read line by line\n",
      "    51 157.1523 MiB   0.0000 MiB      117408           for index,line in enumerate(file):\n",
      "    52                                                     # Load the json\n",
      "    53 157.1523 MiB   0.8750 MiB      117407               line_as_file = io.StringIO(line)\n",
      "    54 157.1523 MiB   0.0000 MiB      117407               json_parser = ijson.parse(line_as_file)\n",
      "    55 157.1523 MiB   4.0000 MiB     1761105               for prefix,event,value in json_parser:\n",
      "    56 157.1523 MiB   0.0000 MiB     1761105                   if prefix == 'date':\n",
      "    57 157.1523 MiB   0.1250 MiB      117407                       date = datetime.strptime(value, \"%Y-%m-%dT%H:%M:%S%z\").date()                    \n",
      "    58 157.1523 MiB   0.0000 MiB     1643698                   elif prefix == 'user.username':\n",
      "    59 157.1523 MiB   0.0000 MiB      117407                       username = value       \n",
      "    60 157.1523 MiB   0.0000 MiB      117407                       if date:        \n",
      "    61 157.1523 MiB   0.0000 MiB      117407                           break\n",
      "    62 157.1523 MiB   0.1250 MiB      117407               tweets_dict[date][username] += 1    \n",
      "    63 157.1523 MiB   0.0000 MiB           1       tweets_dates = tweets_dict.keys()\n",
      "    64 157.1523 MiB   0.0000 MiB          27       tweets_dates = sorted(tweets_dates, key=lambda x: sum(tweets_dict[x].values()), reverse=True)[:10]\n",
      "    65 157.1523 MiB   0.0000 MiB          11       tweets_users = [max(tweets_dict[date],key=tweets_dict[date].get) for date in tweets_dates]\n",
      "    66 157.1523 MiB   0.0000 MiB           1       return list(zip(tweets_dates, tweets_users))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory_ijson\n",
    "result = q1_memory_ijson(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
